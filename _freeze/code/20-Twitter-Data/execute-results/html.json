{
  "hash": "6ea29a2f536a947c44e44eeeac7bbb3c",
  "result": {
    "markdown": "# Twitter Data Collection & Analysis\n\nIn this lesson, we're going to learn how to analyze and explore Twitter data with the Python/command line tool [twarc](https://twarc-project.readthedocs.io/en/latest/). We're specifically going to work with [twarc2](https://twarc-project.readthedocs.io/en/latest/twarc2/), which is designed for version 2 of the Twitter API (released in 2020) and the Academic Research track of the Twitter API (released in 2021), which enables researchers to collect tweets from the entire Twitter archive for free.\n\nTwarc was developed by a project called [Documenting the Now](https://www.docnow.io/). The DocNow team develops tools and ethical frameworks for social media research.\n\n## Dataset\n\n<blockquote class=\"epigraph\" style=\" padding: 10px\">\n    \n[David Foster Wallace]...has become lit-bro shorthand...Make a passing reference to the “David Foster Wallace fanboy” and you can assume the reader knows whom you’re talking about.<p class =\"attribution\">—Molly Fischer,\n<a href=\"https://slate.com/culture/2015/08/men-who-love-david-foster-wallace-what-s-wrong-with-bros-obsessing-over-infinite-jest.html\">\"David Foster Wallace, Beloved Author of Bros\"</a>\n    </p>\n    \n</blockquote>\n\n![](https://static01.nyt.com/images/2014/12/18/arts/18book-sub/BOOK-1418838418938-superJumbo.jpg?quality=90&auto=webp)\n*Source: [Giovanni Giovanetti, NYT](https://www.nytimes.com/2014/12/18/books/the-david-foster-wallace-reader-a-compilation.html)*\n\nThe Twitter conversation that we're going to explore in this lesson is related to \"Wallace bros\" — fans of the author David Foster Wallace who are often described as \"bros\" or, more pointedly, \"David Foster Wallace bros.\"\n\nFor example, in *Slate* in 2015, Molly Fischer argued that David Foster Wallace's writing — most famously his novel *Infinite Jest* — tended to attract  [a fan base of chauvinistic and misogynistic young men](https://slate.com/culture/2015/08/men-who-love-david-foster-wallace-what-s-wrong-with-bros-obsessing-over-infinite-jest.html). But other people  have defended Wallace's fans and the author against such charges. What is a \"David Foster Wallace bro\"? Was DFW himself a \"bro\"? Who is using this phrase, how often are they using it, and why? We're going to track this phrase and explore the varied viewpoints in this cultural conversation by analyzing tweets that mention \"David Foster Wallace bro.\"\n\n## Search Queries & Privacy Concerns\n\nTo collect tweets from the Twitter API, we need to make queries, or requests for specific kinds of tweets — e.g., `twarc2 search *query*`. The simplest kind of query is a keyword search, such as the phrase \"David Foster Wallace bro,\" which should return any tweet that contains all of these words in any order — `twarc2 search \"David Foster Wallace bro\"`.\n\nThere are many other operators that we can add to a query, which would allow us to collect tweets only from specific Twitter users or locations, or to only collect tweets that meet certain conditions, such as containing an image or being authored by a verified Twitter user. Here's an excerpted table of search operators taken from [Twitter's documentation](https://developer.twitter.com/en/docs/twitter-api/tweets/search/integrate/build-a-query#list) about how to build a search query. There are many other operators beyond those included in this table, and I recommend reading through [Twitter's entire web page on this subject](https://developer.twitter.com/en/docs/twitter-api/tweets/search/integrate/build-a-query#list).\n\n\n| Search Operator             | Explanation                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n|:--------------------:|:----------------------------------------------------------------------------------------------:|\n| keyword              | Matches a keyword within the body of a Tweet. `so sweet and so cold`                                                                                          \n| \"exact phrase match\" | Matches the exact phrase within the body of a Tweet. `\"so sweet and so cold\" OR \"plums in the icebox\"`                                                                                              |\n| - | Do NOT match a keyword or operator `baldwin -alec`, `walt whitman -bridge`                                                                                              |\n| #                    | Matches any Tweet containing a recognized hashtag `#arthistory`        |                                                                             |\n| from:, to:                | Matches any Tweet from or to a specific user. `from:KingJames` `to:KingJames`                                                                    |                                                                                                            |\n| place:               | Matches Tweets tagged with the specified location or Twitter place ID. `place:\"new york city\" OR place:seattle`                                                                                            |\n| is:reply, is:quote             | Returns only replies or quote tweets. `DFW bro is:reply` `David Foster Wallace bro is:quote`                                                                                                                               |\n| is:verified          | Returns only Tweets whose authors are verified by Twitter.`DFW bro is:verified`                                                                                                                                |\n| has:media           | Matches Tweets that contain a media object, such as a photo, GIF, or video, as determined by Twitter. `I Think You Should Leave has:media`                                                                                                                                |\n| has:images, has:videos           | Matches Tweets that contain a recognized URL to an image. `i'm gonna tell my kinds that this was has:images`                                                                                    |\n| has:geo              | Matches Tweets that have Tweet-specific geolocation data provided by the Twitter user.  `pyramids has:geo`              \n\nIn this lesson, we will only be collecting tweets that were tweeted by verified users: `\"David Foster Wallace bro is:verified\"`.\n\nAs I discussed in [\"Users’ Data: Legal & Ethical Considerations,\"](01-User-Ethics-Legal-Concerns) collecting publicly available tweets is legal, but it still raises a lot of privacy concerns and ethical quandaries — particularly when you re-publish user's data, as I am in this lesson. To reduce potential harm to Twitter users when re-publishing or citing tweets, it can be helpful to ask for explicit permission from the authors or to focus on tweets that have already been reasonably exposed to the public (e.g., tweets with many retweets or tweets from verified users), such that re-publishing the content will not unduly increase risk to the user.\n               \n\n## Install and Import Libraries\n\nBecause twarc relies on Twitter's API, we need to apply for a Twitter developer account and create a Twitter application before we can use it. You can find instructions for the application process in [\"Twitter API Set Up.\"](11-Twitter-API-Setup)\n\nIf you haven't done so already, you need to install twarc and configure twarc with your bearer token and/or API keys.\n\n::: {.cell ExecuteTime='{\"end_time\":\"2022-11-07T15:32:39.424764Z\",\"start_time\":\"2022-11-07T15:32:39.419379Z\"}' execution_count=1}\n``` {.python .cell-code}\n#!pip install twarc\n#!twarc2 configure\n```\n:::\n\n\nTo make an interactive plot, we're also going to install the package plotly.\n\n::: {.cell ExecuteTime='{\"end_time\":\"2022-11-07T15:32:42.628302Z\",\"start_time\":\"2022-11-07T15:32:40.157351Z\"}' execution_count=2}\n``` {.python .cell-code}\n# !pip install plotly\n```\n:::\n\n\nThen we're going to import plotly as well as pandas\n\n::: {.cell ExecuteTime='{\"end_time\":\"2022-11-07T15:32:49.706387Z\",\"start_time\":\"2022-11-07T15:32:49.700585Z\"}' execution_count=3}\n``` {.python .cell-code}\nimport plotly.express as px\n\nimport pandas as pd\npd.options.display.max_colwidth = 400\npd.options.display.max_columns = 90\n```\n:::\n\n\n## Get Tweet Counts\n\nThe first thing we're going to do is retrieve \"tweet counts\" — that is, retrieve the number of tweets that included the phrase \"David Foster Wallace bro\" each day in Twitter's history.\n\nThe [tweet counts API endpoint](https://twittercommunity.com/t/introducing-new-tweet-counts-endpoints-to-the-twitter-api-v2/155997) is a convenient feature of the v2 API (first introduced in 2021) that allows us to get a sense of how many tweets will be returned for a given query before we actually collect all the tweets that match the query. We won't get the text of the tweets or the users who tweeted the tweets or any other relevant data. We will simply get the number of tweets that match the query. This is helpful because we might be able to see that the search query \"Wallace\" matches too many tweets, which would encourage us to narrow our search by modifying the query. \n\nThe tweet counts API endpoint is perhaps even more useful for research projects that are primarily interested in tracking the volume of a Twitter conversation over time. In this case, tweet counts enable a researcher to retrieve this information in a way that's faster and easier than retrieving all tweets and relevant metadata.\n\nTo get tweet counts from Twitter's entire history with twarc2, we will use [`twarc2 counts`](https://twarc-project.readthedocs.io/en/latest/twarc2/#counts) followed by a search query.\n\nWe will also use the flag `--csv` because we want to output the data as a CSV, the flag `--archive` because we're working with the Academic Research track of the Twitter API and want access to the full archive, and the flag `--granularity day` to get tweet counts per day (other options include `hour` and `minute` — you can see more in [twarc's documentation](https://twarc-project.readthedocs.io/en/latest/twarc2/#counts)).  Finally, we write the data to a CSV file.\n\n::: {.cell ExecuteTime='{\"end_time\":\"2022-11-07T15:32:51.249336Z\",\"start_time\":\"2022-11-07T15:32:51.244748Z\"}' execution_count=4}\n``` {.python .cell-code}\n# !twarc2 counts \"David Foster Wallace bro is:verified\" --csv --archive --granularity day > twitter-data/tweet-counts.csv\n```\n:::\n\n\nWe can read in this CSV file with pandas, parse the date columns, and sort from earliest to latest. The code below is largely [borrowed from Ed Summers](https://github.com/edsu/notebooks/blob/master/Black%20Lives%20Matter%20Counts.ipynb). Thanks, Ed!\n\n<div class=\"admonition pandasreview\" name=\"html-admonition\" style=\"background: black; color: white; padding: 10px\">\n<p class=\"title\">Pandas</p>\n Do you need a refresher or introduction to the Python data analysis library Pandas? Be sure to check out <a href=\"https://melaniewalsh.github.io/Intro-Cultural-Analytics/Data-Analysis/Pandas-Basics-Part1.html\"> Pandas Basics (1-3) </a> in this textbook!\n    \n</div>\n\n::: {.cell ExecuteTime='{\"end_time\":\"2022-11-07T15:32:52.804092Z\",\"start_time\":\"2022-11-07T15:32:52.797353Z\"}' execution_count=5}\n``` {.python .cell-code}\n# Code borrowed from Ed Summers\n# https://github.com/edsu/notebooks/blob/master/Black%20Lives%20Matter%20Counts.ipynb\n\n# Read in CSV as DataFrame\n# tweet_counts_df = pd.read_csv('twitter-data/tweet-counts.csv', parse_dates=['start', 'end'])\n# Sort values by earliest date\n# tweet_counts_df = tweet_counts_df.sort_values('start')\n# tweet_counts_df\n```\n:::\n\n\nThen we can make a quick plot of tweets per day with [plotly](https://plotly.com/python/line-charts/)\n\n::: {.cell ExecuteTime='{\"end_time\":\"2022-11-07T15:32:53.826173Z\",\"start_time\":\"2022-11-07T15:32:53.820572Z\"}' execution_count=6}\n``` {.python .cell-code}\n# Code borrowed from Ed Summers\n# https://github.com/edsu/notebooks/blob/master/Black%20Lives%20Matter%20Counts.ipynb\n# Make a line plot from the DataFrame and specify x and y axes, axes titles, and plot title\n# figure = px.line(tweet_counts_df, x='start', y='day_count',\n#     labels={'start': 'Time', 'day_count': 'Tweets per Day'},\n#     title= 'DFW Bro Tweets'\n# )\n\n# figure.show()\n```\n:::\n\n\nWith a plotly line chart, we can hover over points to see more information, and we can use the tool bar in the upper right corner to zoom or pan on different parts of the graph. We can also press the camera button to download an image of the graph at any pan or zoom level.\n\nTo return to the original view, double-click on the plot.\n\n## Get Tweets (Standard Track)\n\nTo actually collect tweets and their associated metadata, we can use the command `twarc2 search` and insert a query.\n\nHere we're going to search for any tweets that mention the words \"David Foster Wallace bro\" and were tweeted by verified accounts *in the past week*. By default, `twarc2 search` will use the standard track of the Twitter API, which only collects tweets from the past week.\n\n::: {.cell ExecuteTime='{\"end_time\":\"2022-11-07T15:32:54.860952Z\",\"start_time\":\"2022-11-07T15:32:54.856395Z\"}' tags='[\"output_scroll\"]' execution_count=7}\n``` {.python .cell-code}\n# !twarc2 search \"David Foster Wallace is:verified\"\n```\n:::\n\n\nhttps://github.com/melaniewalsh/Intro-Cultural-AnalyticsThe tweets and tweet metadata above are being printed to the notebook. But we want to save this information to a file so we can work with it.\n\nTo output Twitter data to a file, we can also include a filename with the \".jsonl\" file extension, which stands for JSON lines, a special kind of JSON file.\n\n::: {.cell ExecuteTime='{\"end_time\":\"2022-11-07T15:32:56.027360Z\",\"start_time\":\"2022-11-07T15:32:56.021313Z\"}' execution_count=8}\n``` {.python .cell-code}\n# !twarc2 search \"David Foster Wallace is:verified\" twitter-data/dfw_last_week.jsonl\n```\n:::\n\n\nTheoretically, a tweet with \"David,\" \"Foster\", and \"Wallace\" in different places would be matched by the more general search above. If we wanted to match the words \"David Foster Wallace\" exactly, we would need to put \"David Foster Wallace\" in quotation marks *and* \"escape\" those quotation marks, so that `twarc2` will know that our query shouldn't end at the next quotation mark.\n\n::: {.cell ExecuteTime='{\"end_time\":\"2022-11-07T15:33:14.727512Z\",\"start_time\":\"2022-11-07T15:33:14.725225Z\"}' execution_count=9}\n``` {.python .cell-code}\n# !twarc2 search \"\\\"David Foster Wallace\\\" is:verified\" twitter-data/dfw_exact.jsonl\n```\n:::\n\n\nIf you're working on a Mac, you should be able to escape the quotation marks with backslashes `\\` before the characters, as shown in the example above. But if you're working on a Windows computer, you may need to use triple quotations instead, for example:\n\n`twarc2 search \"\"\" \"David Foster Wallace\" is:verified\"\"\" twitter-data/dfw_exact.jsonl`\n\n## Get Tweets (Academic Track, Full Twitter Archive)\n\n\n<div class=\"admonition attention\" name=\"html-admonition\" style=\"background: lightyellow; padding: 10px\">\n<p class=\"title\">Attention</p>\nRemember that this functionality is only available to those who have an [Academic Research account](https://developer.twitter.com/en/products/twitter-api/academic-research).\n\n</div>\n\nTo collect tweets from Twitter's entire historical archive, we need to add the `--archive` flag.\n\n::: {.cell ExecuteTime='{\"end_time\":\"2022-11-07T15:33:14.736061Z\",\"start_time\":\"2022-11-07T15:33:14.733974Z\"}' execution_count=10}\n``` {.python .cell-code}\n# !twarc2 search \"David Foster Wallace bro is:verified\" --archive twitter-data/dfw_bro.jsonl\n```\n:::\n\n\n## Convert JSONL to CSV\n\nTo make our Twitter data easier to work with, we can convert our JSONL file to a CSV file with the [`twarc-csv`](https://pypi.org/project/twarc-csv/) plugin, which needs to be installed separately.\n\n::: {.cell ExecuteTime='{\"end_time\":\"2022-11-07T15:33:18.135317Z\",\"start_time\":\"2022-11-07T15:33:18.132310Z\"}' execution_count=11}\n``` {.python .cell-code}\n# !pip install twarc-csv\n```\n:::\n\n\nOnce installed, we can use the plug-in from twarc2 with the input filename for the JSONL and a desired output filename for the CSV file.\n\n::: {.cell ExecuteTime='{\"end_time\":\"2022-11-07T15:33:18.941017Z\",\"start_time\":\"2022-11-07T15:33:18.934936Z\"}' execution_count=12}\n``` {.python .cell-code}\n# !twarc2 csv twitter-data/dfw_bro.jsonl twitter-data/dfw_bro.csv\n```\n:::\n\n\nBy default, when converting from the JSONL file, `twarc-csv` will only include tweets that were directly returned from the search.\n\nIf you want you can also use `--inline-referenced-tweets` option to make \"referenced\" tweets into their own rows in the CSV file. For example, if a quote tweet matched our query, the tweet being quoted would also be included in the CSV file as its own row, even if it didn't match our query. But as of v0.5.0 of twarc-csv this is no longer the default behavior.\n\n## Read in CSV\n\nNow we're ready to explore the data!\n\nTo work with our tweet data, we can read in our CSV file with pandas and again parse the date column.\n\n::: {.cell ExecuteTime='{\"end_time\":\"2022-11-07T15:33:19.973898Z\",\"start_time\":\"2022-11-07T15:33:19.969084Z\"}' execution_count=13}\n``` {.python .cell-code}\n# tweets_df = pd.read_csv('twitter-data/dfw_bro.csv',\n#                         parse_dates = ['created_at'])\n```\n:::\n\n\nIf we scroll through this dataset, we can see that there are only 29 tweets that matched our search query, but there is a *lot* of metadata associated with each tweet. Scroll to the right to see all the information. What category surprises you the most? (For me, it's the tweet author's pinned tweet from their own timeline. Your pinned tweet gets attached to everything else you tweet!)\n\n::: {.cell ExecuteTime='{\"end_time\":\"2022-11-07T15:33:20.911175Z\",\"start_time\":\"2022-11-07T15:33:20.906749Z\"}' tags='[\"output_scroll\",\"full-width\"]' execution_count=14}\n``` {.python .cell-code}\n# tweets_df\n```\n:::\n\n\nIf we ask for a list of all the columns in the DataFrame, we can see that there are more than 90 columns here!\n\n::: {.cell ExecuteTime='{\"end_time\":\"2022-11-07T15:33:25.889561Z\",\"start_time\":\"2022-11-07T15:33:25.884789Z\"}' tags='[\"output_scroll\"]' execution_count=15}\n``` {.python .cell-code}\n# tweets_df.columns\n```\n:::\n\n\nAs you experiment with the query syntax provided by the Twitter API you should make a habit of scanning through your collected Twitter data to ensure that your API query and subsequent manipulations are returning the data that you expect and want. If you notice tweets you don't expect return to examine your query to see if you can explain why those tweets are turning up. If you can't find an adequate explanation you might want to ask in the [Twitter Community Forum](https://twittercommunity.com).\n\n## Extract Tweet and Media URLs\n\nWe can make some Python functions that will create a tweet URL based on each tweet's unique ID as well as extract an image URL if one exists.\n\n::: {.cell ExecuteTime='{\"end_time\":\"2022-11-07T15:33:26.685505Z\",\"start_time\":\"2022-11-07T15:33:26.672283Z\"}' execution_count=16}\n``` {.python .cell-code}\n# Make Tweet URL\ndef make_tweet_url(tweets):\n    # Get username\n    username = tweets[0]\n    # Get tweet ID\n    tweet_id = tweets[1]\n    # Make tweet URL\n    tweet_url = f\"https://twitter.com/{username}/status/{tweet_id}\"\n    return tweet_url\n\n# Extract Image URL\nfrom ast import literal_eval\ndef get_image_url(media):\n    # if not NaN or {}\n    if type(media) != float and media != '{}':\n        # Convert to an actual Python list, not just a string\n        media =  literal_eval(media)\n        media = media[0]\n         # Extract media url if it exists\n        if 'url' in media.keys():\n            return media['url']\n    else:\n        return \"No Image URL\"\n```\n:::\n\n\nHere we apply the above Python functions to the relevant columns to create new columns.\n\n::: {.cell ExecuteTime='{\"end_time\":\"2022-11-07T15:33:27.665155Z\",\"start_time\":\"2022-11-07T15:33:27.659390Z\"}' execution_count=17}\n``` {.python .cell-code}\n# tweets_df['tweet_url'] = tweets_df[['author.username', 'id']].apply(make_tweet_url, axis='columns')\n# tweets_df['media'] = tweets_df['attachments.media'].apply(get_image_url)\n```\n:::\n\n\n## Rename and Select Columns\n\nTo make the data more readable, we're going to rename a number of columns.\n\n::: {.cell ExecuteTime='{\"end_time\":\"2022-11-07T15:33:28.752283Z\",\"start_time\":\"2022-11-07T15:33:28.745278Z\"}' tags='[]' execution_count=18}\n``` {.python .cell-code}\n# tweets_df.rename(columns={'created_at': 'date',\n#                           'public_metrics.retweet_count': 'retweets', \n#                           'author.username': 'username', \n#                           'author.name': 'name',\n#                           'author.verified': 'verified', \n#                           'public_metrics.like_count': 'likes', \n#                           'public_metrics.quote_count': 'quotes', \n#                           'public_metrics.reply_count': 'replies',\n#                            'author.description': 'user_bio'},\n#                             inplace=True)\n```\n:::\n\n\nThen we're only going to select the columns that we're interested. Depending on your project and research question, you should change and customize these categories.\n\n::: {.cell ExecuteTime='{\"end_time\":\"2022-11-07T15:33:29.516229Z\",\"start_time\":\"2022-11-07T15:33:29.513335Z\"}' execution_count=19}\n``` {.python .cell-code}\n# tweets_df = tweets_df[['date', 'username', 'name', 'verified', 'text', 'retweets',\n#            'likes', 'replies',  'quotes', 'tweet_url', 'media', 'user_bio']]\n```\n:::\n\n\nNow we can view our more focused DataFrame!\n\n::: {.cell ExecuteTime='{\"end_time\":\"2022-11-07T15:33:30.086443Z\",\"start_time\":\"2022-11-07T15:33:30.081054Z\"}' tags='[\"output_scroll\"]' execution_count=20}\n``` {.python .cell-code}\n# tweets_df\n```\n:::\n\n\n## Sort By Top Retweets\n\nWe can sort by number of retweets to see the most circulated tweets. Let's examine the top 5.\n\n::: {.cell ExecuteTime='{\"end_time\":\"2022-11-07T15:33:31.403803Z\",\"start_time\":\"2022-11-07T15:33:31.398499Z\"}' tags='[\"full-width\"]' execution_count=21}\n``` {.python .cell-code}\n# tweets_df.sort_values(by='retweets', ascending=False)[:5]\n```\n:::\n\n\nHere is the most retweeted tweet in this dataset:\n\n<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">david foster wallace bro conversation again? i feel like by this point in the discourse i need footnotes! (just a little &quot;insider&quot; dfw humor for ya)</p>&mdash; David Grossman (@davidgross_man) <a href=\"https://twitter.com/davidgross_man/status/1297936487909130240?ref_src=twsrc%5Etfw\">August 24, 2020</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script> \n\n## Sort By Date\n\nWe can sort from the earliest tweets to the latest tweets. Let's examine the earliest 5 tweets.\n\n::: {.cell ExecuteTime='{\"end_time\":\"2022-11-07T15:33:32.312358Z\",\"start_time\":\"2022-11-07T15:33:32.307795Z\"}' tags='[\"full-width\"]' execution_count=22}\n``` {.python .cell-code}\n# tweets_df.sort_values(by='date', ascending=True)[:5]\n```\n:::\n\n\nThe earliest tweet in this dataset is from the music label Melodic Records:\n\n<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\"><a href=\"https://twitter.com/MelodicRecords?ref_src=twsrc%5Etfw\">@MelodicRecords</a> chillax brother, we all gud. Put another blunt on the barbie &#39;n&#39; go wid th&#39; flo bro. Dude man... <a href=\"http://t.co/q0RUmv12\">http://t.co/q0RUmv12</a></p>&mdash; Drowned in Sound ⚓️ (@DrownedinSound) <a href=\"https://twitter.com/DrownedinSound/status/146330510422048768?ref_src=twsrc%5Etfw\">December 12, 2011</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script> \n\n## Plot Tweets Over Time\n\nAn easy way to create a plot of tweets over time is to add a column with a 1 for every row, which we can use to count how many tweets were published per day, week, month, or year.\n\n::: {.cell ExecuteTime='{\"end_time\":\"2022-11-07T15:33:33.286033Z\",\"start_time\":\"2022-11-07T15:33:33.280704Z\"}' execution_count=23}\n``` {.python .cell-code}\n# tweets_df = tweets_df.assign(count=1)\n```\n:::\n\n\nWe also need to set the date column to the index so we can do some special date manipulations.\n\n::: {.cell ExecuteTime='{\"end_time\":\"2022-11-07T15:33:33.733916Z\",\"start_time\":\"2022-11-07T15:33:33.728369Z\"}' tags='[\"output_scroll\"]' execution_count=24}\n``` {.python .cell-code}\n# tweets_df = tweets_df.set_index('date')\n# tweets_df\n```\n:::\n\n\nBecause our index is a datetime value, we can use the special Pandas method [`.resample()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.resample.html) to group the tweets by month, add them up, and plot them over time.\n\n::: {.cell ExecuteTime='{\"end_time\":\"2022-11-07T15:33:34.262440Z\",\"start_time\":\"2022-11-07T15:33:34.257280Z\"}' execution_count=25}\n``` {.python .cell-code}\n# tweets_df['count'].resample('M').sum()\\\n# .plot(title='\"David Foster Wallace Bro\"\\n Tweets from Verified Accounts');\n```\n:::\n\n\n## Display Links and Images in Twitter Data\n\nTo display links and images in our DataFrame, we can convert the image URL into an HTML image tag, and we can display our DataFrame as an HTML object with the `HTML` module.\n\n::: {.cell ExecuteTime='{\"end_time\":\"2022-11-07T15:33:35.336334Z\",\"start_time\":\"2022-11-07T15:33:35.327816Z\"}' tags='[\"output_scroll\"]' execution_count=26}\n``` {.python .cell-code}\nfrom IPython.core.display import HTML\n\ndef get_image_html(link):\n    # check to see if the media category has an image URL\n    if link != \"No Image URL\":\n        # format the image url as an HTML image\n        image_html = f\"<a href='{link}'>'<img src='{link}' width='500px'></a>                            \"\n        return image_html\n    else:\n        return \"No Image URL\"\n# Apply the above function to the media column\n# tweets_df['media']= tweets_df['media'].apply(get_image_html)\n```\n:::\n\n\nView images\n\n::: {.cell ExecuteTime='{\"end_time\":\"2022-11-07T15:33:35.836339Z\",\"start_time\":\"2022-11-07T15:33:35.829596Z\"}' tags='[\"output_scroll\",\"full-width\"]' execution_count=27}\n``` {.python .cell-code}\n# HTML(tweets_df[['media', 'text']].sort_values(by='media').to_html(render_links=True, escape=False))\n```\n:::\n\n\nView tweet links\n\n::: {.cell ExecuteTime='{\"end_time\":\"2022-11-07T15:33:36.515692Z\",\"start_time\":\"2022-11-07T15:33:36.510666Z\"}' tags='[\"full-width\",\"output_scroll\"]' execution_count=28}\n``` {.python .cell-code}\n# HTML(tweets_df[['tweet_url', 'text', 'retweets']].sort_values(by='retweets', ascending=False).to_html(render_links=True, escape=False))\n```\n:::\n\n\n## Top Hashtags\n\nTo analyze hashtags in a tweet dataset, we can use the plugin [`twarc2 hashtags`](https://pypi.org/project/twarc-hashtags/), which requires a separate installation.\n\n::: {.cell ExecuteTime='{\"end_time\":\"2022-11-07T15:33:39.757921Z\",\"start_time\":\"2022-11-07T15:33:37.266723Z\"}' execution_count=29}\n``` {.python .cell-code}\n!pip install twarc-hashtags\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRequirement already satisfied: twarc-hashtags in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (0.0.5)\r\nRequirement already satisfied: twarc>=2.1.1 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from twarc-hashtags) (2.12.0)\r\nRequirement already satisfied: python-dateutil>=2.8 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from twarc>=2.1.1->twarc-hashtags) (2.8.2)\r\nRequirement already satisfied: humanize>=3.9 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from twarc>=2.1.1->twarc-hashtags) (3.13.1)\r\nRequirement already satisfied: click-config-file>=0.6 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from twarc>=2.1.1->twarc-hashtags) (0.6.0)\r\nRequirement already satisfied: click-plugins>=1 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from twarc>=2.1.1->twarc-hashtags) (1.1.1)\r\nRequirement already satisfied: click<9,>=7 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from twarc>=2.1.1->twarc-hashtags) (8.1.3)\r\nRequirement already satisfied: tqdm>=4.62 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from twarc>=2.1.1->twarc-hashtags) (4.64.0)\r\nRequirement already satisfied: requests-oauthlib>=1.3 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from twarc>=2.1.1->twarc-hashtags) (1.3.1)\r\nRequirement already satisfied: configobj>=5.0.6 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from click-config-file>=0.6->twarc>=2.1.1->twarc-hashtags) (5.0.6)\r\nRequirement already satisfied: six>=1.5 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.8->twarc>=2.1.1->twarc-hashtags) (1.16.0)\r\nRequirement already satisfied: oauthlib>=3.0.0 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=1.3->twarc>=2.1.1->twarc-hashtags) (3.2.0)\r\nRequirement already satisfied: requests>=2.0.0 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=1.3->twarc>=2.1.1->twarc-hashtags) (2.28.1)\r\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nRequirement already satisfied: certifi>=2017.4.17 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.0.0->requests-oauthlib>=1.3->twarc>=2.1.1->twarc-hashtags) (2022.9.24)\r\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.0.0->requests-oauthlib>=1.3->twarc>=2.1.1->twarc-hashtags) (1.26.11)\r\nRequirement already satisfied: charset-normalizer<3,>=2 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.0.0->requests-oauthlib>=1.3->twarc>=2.1.1->twarc-hashtags) (2.0.12)\r\nRequirement already satisfied: idna<4,>=2.5 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.0.0->requests-oauthlib>=1.3->twarc>=2.1.1->twarc-hashtags) (3.3)\r\n```\n:::\n:::\n\n\nThen we can create a CSV digest of the top hashtags from our JSONL data with `twarc2 hashtags`. (To get more hashtag data, we are using a JSONL file that contains a full archive search of \"David Foster Wallace\" rather than \"David Foster Wallace bro\").\n\n::: {.cell ExecuteTime='{\"end_time\":\"2022-11-07T15:33:39.769217Z\",\"start_time\":\"2022-11-07T15:33:39.766986Z\"}' execution_count=30}\n``` {.python .cell-code}\n# !twarc2 hashtags twitter-data/dfw.jsonl twitter-data/dfw_hashtags.csv\n```\n:::\n\n\n::: {.cell ExecuteTime='{\"end_time\":\"2022-11-07T15:33:39.779869Z\",\"start_time\":\"2022-11-07T15:33:39.777699Z\"}' execution_count=31}\n``` {.python .cell-code}\n# pd.read_csv('twitter-data/dfw_hashtags.csv')\n```\n:::\n\n\nWe can also use the flag `--group` to group the hashtags by their frequency per time period and the flag `--limit` to limit the hashtags to only the top *n* number of hashtags per grouping.\n\n::: {.cell ExecuteTime='{\"end_time\":\"2022-11-07T15:33:39.787864Z\",\"start_time\":\"2022-11-07T15:33:39.784948Z\"}' execution_count=32}\n``` {.python .cell-code}\n# !twarc2 hashtags --group year --limit 10 twitter-data/dfw.jsonl twitter-data/dfw_hashtags_year.csv\n```\n:::\n\n\n::: {.cell ExecuteTime='{\"end_time\":\"2022-11-07T15:33:44.237477Z\",\"start_time\":\"2022-11-07T15:33:44.233441Z\"}' execution_count=33}\n``` {.python .cell-code}\n# hashtags_df = pd.read_csv('twitter-data/dfw_hashtags_year.csv')\n# hashtags_df \n```\n:::\n\n\nTo plot the frequency of hashtags over time, we can set the DataFrame index to the \"time\" column.\n\n::: {.cell ExecuteTime='{\"end_time\":\"2022-11-07T15:33:44.599608Z\",\"start_time\":\"2022-11-07T15:33:44.594706Z\"}' execution_count=34}\n``` {.python .cell-code}\n# hashtags_df = hashtags_df.set_index('time')\n```\n:::\n\n\nThen we can filter for a specific hashtag and plot its frequency.\n\n::: {.cell ExecuteTime='{\"end_time\":\"2022-11-07T15:33:44.939559Z\",\"start_time\":\"2022-11-07T15:33:44.934649Z\"}' execution_count=35}\n``` {.python .cell-code}\n# hashtags_df[hashtags_df['hashtag'] == 'writing'].plot(y='tweets', label='#writing', title='DFW Hashtags');\n```\n:::\n\n\nWe can also plot multiple hashtags on the same plot by assigning the first plot to the variable `main_axis` and then directing the next plots to be plotted on the same axis `ax=main_axis`.\n\n::: {.cell ExecuteTime='{\"end_time\":\"2022-11-07T15:33:45.320523Z\",\"start_time\":\"2022-11-07T15:33:45.314275Z\"}' execution_count=36}\n``` {.python .cell-code}\n# main_axis = hashtags_df[hashtags_df['hashtag'] == 'writing'].plot(y='tweets', label='#writing', title='DFW Hashtags')\n# hashtags_df[hashtags_df['hashtag'] == 'dfw'].plot(ax=main_axis, y='tweets', label='#dfw')\n# hashtags_df[hashtags_df['hashtag'] == 'infinitejest'].plot(ax=main_axis, y='tweets', label='#infinitejest');\n```\n:::\n\n\n## Sentiment Analysis \n\nSee an example of running the English-language [sentiment analysis tool VADER on Donald Trump's tweets](../05-Text-Analysis/04-Sentiment-Analysis).\n\n## Topic Modeling Tweets\n\nSee an example of using [topic modeling on Donald Trump's tweets](../05-Text-Analysis/11-Topic-Modeling-Time-Series).\n\n",
    "supporting": [
      "20-Twitter-Data_files"
    ],
    "filters": [],
    "includes": {}
  }
}